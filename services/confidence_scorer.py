# ============================================
# app/services/confidence_scorer.py - Speaker Confidence Scoring
# ============================================

import re
from typing import Dict, Any, List, Tuple
from collections import defaultdict

import numpy as np

from core.logger import get_logger

logger = get_logger()


class ConfidenceScorer:
    """
    Speaker confidence scoring engine.
    Evaluates speaker certainty on a scale from 1 to 10.
    Uses mathematical analysis of speech patterns.
    """
    
    # Confidence indicators (positive)
    CONFIDENCE_MARKERS = {
        "strong_certainty": {
            "words": ["definitely", "certainly", "absolutely", "sure", "confident",
                     "guarantee", "always", "never", "must", "will"],
            "weight": 1.5
        },
        "knowledge_claims": {
            "words": ["know", "understand", "clear", "obvious", "evidence",
                     "fact", "proven", "research shows", "data shows"],
            "weight": 1.3
        },
        "assertive_phrases": {
            "words": ["i believe", "i am sure", "no doubt", "without question",
                     "it is clear", "we know", "the answer is"],
            "weight": 1.4
        },
        "professional_terms": {
            "words": ["specifically", "precisely", "exactly", "technically",
                     "fundamentally", "essentially", "primarily"],
            "weight": 1.2
        }
    }
    
    # Hesitation indicators (negative)
    HESITATION_MARKERS = {
        "uncertainty_words": {
            "words": ["maybe", "perhaps", "possibly", "might", "could be",
                     "not sure", "i think", "i guess", "probably", "seems"],
            "weight": -1.3
        },
        "filler_words": {
            "words": ["um", "uh", "er", "ah", "like", "you know", "basically",
                     "sort of", "kind of", "actually", "literally"],
            "weight": -0.8
        },
        "hedging_phrases": {
            "words": ["i suppose", "it appears", "in my opinion", "from what i see",
                     "to some extent", "more or less", "in a way"],
            "weight": -1.0
        },
        "questioning_self": {
            "words": ["i wonder", "am i right", "is that correct", "does that make sense",
                     "right?", "you know what i mean"],
            "weight": -1.2
        }
    }
    
    # Prosodic confidence indicators
    PROSODIC_THRESHOLDS = {
        "speech_rate": {
            "confident_min": 0.9,
            "confident_max": 1.3,
            "hesitant_min": 0.5,
            "hesitant_max": 0.8
        },
        "pitch_variance": {
            "confident_max": 0.3,  # Lower variance = more confident
            "hesitant_min": 0.5   # Higher variance = less confident
        },
        "pause_ratio": {
            "confident_max": 0.15,  # Less than 15% pauses
            "hesitant_min": 0.3     # More than 30% pauses
        }
    }
    
    def __init__(self):
        self.score_history: List[float] = []
        self.loaded = False
    
    
    def load(self):
        """Load confidence scorer resources."""
        # Initialize any resources needed for confidence scoring
        self.loaded = True
        logger.info("âœ… Confidence Scorer loaded")
    
    def score(
        self,
        audio: np.ndarray = None,
        text: str = "",
        transcription_confidence: float = 1.0,
        emotions: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Score speaker confidence (test-compatible wrapper).
        
        Args:
            audio: Audio array (optional)
            text: Transcribed text
            transcription_confidence: Confidence from transcription
            emotions: Emotion analysis results
            
        Returns:
            Confidence analysis results
        """
        # Extract audio features if audio provided
        audio_features = {}
        if audio is not None:
            import numpy as np
            audio_features = {
                "energy_mean": float(np.mean(audio ** 2)),
                "energy_variance": float(np.std(audio ** 2)) / (float(np.mean(audio ** 2)) + 1e-6),
                "pitch_variance": 0.3,
                "speech_rate": 1.0
            }
        else:
            audio_features = {
                "energy_mean": 0.1,
                "energy_variance": 0.3,
                "pitch_variance": 0.3,
                "speech_rate": 1.0
            }
        
        # Use analyze() method
        emotion_analysis = emotions if emotions else {
            "primary_emotion": "neutral",
            "primary_score": 0.5,
            "emotional_stability": 0.5
        }
        
        return self.analyze(text, audio_features, emotion_analysis)

    def analyze(
        self,
        text: str,
        audio_features: Dict[str, float],
        emotion_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Analyze speaker confidence.
        
        Args:
            text: Transcribed text
            audio_features: Extracted audio features
            emotion_analysis: Emotion detection results
            
        Returns:
            Complete confidence analysis
        """
        # Analyze linguistic confidence
        linguistic_score, linguistic_details = self._analyze_linguistic_confidence(text)
        
        # Analyze prosodic confidence
        prosodic_score, prosodic_details = self._analyze_prosodic_confidence(audio_features)
        
        # Factor in emotional state
        emotional_adjustment = self._calculate_emotional_adjustment(emotion_analysis)
        
        # Calculate sentence structure confidence
        structure_score = self._analyze_sentence_structure(text)
        
        # Calculate vocabulary sophistication
        vocabulary_score = self._analyze_vocabulary(text)
        
        # Combine all components
        components = {
            "linguistic": linguistic_score,
            "prosodic": prosodic_score,
            "emotional": emotional_adjustment,
            "structure": structure_score,
            "vocabulary": vocabulary_score
        }
        
        # Weighted combination
        weights = {
            "linguistic": 0.35,
            "prosodic": 0.25,
            "emotional": 0.15,
            "structure": 0.15,
            "vocabulary": 0.10
        }
        
        raw_score = sum(components[k] * weights[k] for k in components)
        
        # Scale to 1-10
        final_score = self._scale_score(raw_score)
        
        # Determine certainty level
        certainty_level = self._get_certainty_level(final_score)
        
        # Collect all markers found
        hesitation_markers = linguistic_details.get("hesitation_words", [])
        confidence_markers = linguistic_details.get("confidence_words", [])
        
        # Generate analysis notes
        notes = self._generate_analysis_notes(
            final_score, components, linguistic_details, prosodic_details
        )
        
        # Track history
        self.score_history.append(final_score)
        if len(self.score_history) > 100:
            self.score_history.pop(0)
        
        return {
            "overall_score": round(final_score, 2),
            "certainty_level": certainty_level,
            "certainty_indicators": confidence_markers[:10],  # For test compatibility
            "components": {k: round(v, 4) for k, v in components.items()},
            "hesitation_markers": hesitation_markers[:10],
            "confidence_markers": confidence_markers[:10],
            "analysis_notes": notes,
            "details": {
                "linguistic": linguistic_details,
                "prosodic": prosodic_details,
                "word_count": len(text.split()) if text else 0,
                "sentence_count": len(re.split(r'[.!?]+', text)) if text else 0
            }
        }
    
    def _analyze_linguistic_confidence(self, text: str) -> Tuple[float, Dict[str, Any]]:
        """Analyze confidence based on word choice."""
        if not text:
            return 0.5, {"confidence_words": [], "hesitation_words": [], "raw_score": 0}
        
        lower_text = text.lower()
        word_count = len(text.split())
        
        confidence_score = 0.0
        hesitation_score = 0.0
        confidence_words = []
        hesitation_words = []
        
        # Check confidence markers
        for category, data in self.CONFIDENCE_MARKERS.items():
            for word in data["words"]:
                count = lower_text.count(word.lower())
                if count > 0:
                    confidence_score += count * data["weight"]
                    confidence_words.append(word)
        
        # Check hesitation markers
        for category, data in self.HESITATION_MARKERS.items():
            for word in data["words"]:
                count = lower_text.count(word.lower())
                if count > 0:
                    hesitation_score += count * abs(data["weight"])
                    hesitation_words.append(word)
        
        # Normalize by word count
        if word_count > 0:
            confidence_score = confidence_score / word_count * 10
            hesitation_score = hesitation_score / word_count * 10
        
        # Calculate net score (0-1 range)
        net_score = 0.5 + (confidence_score - hesitation_score) * 0.1
        net_score = max(0.1, min(0.95, net_score))
        
        return net_score, {
            "confidence_words": list(set(confidence_words)),
            "hesitation_words": list(set(hesitation_words)),
            "confidence_score": confidence_score,
            "hesitation_score": hesitation_score,
            "raw_score": confidence_score - hesitation_score
        }
    
    def _analyze_prosodic_confidence(
        self,
        audio_features: Dict[str, float]
    ) -> Tuple[float, Dict[str, Any]]:
        """Analyze confidence based on speech prosody."""
        score = 0.5
        details = {}
        
        # Speech rate analysis
        speech_rate = audio_features.get("speech_rate", 1.0)
        thresholds = self.PROSODIC_THRESHOLDS["speech_rate"]
        
        if thresholds["confident_min"] <= speech_rate <= thresholds["confident_max"]:
            score += 0.15
            details["speech_rate_assessment"] = "optimal"
        elif speech_rate < thresholds["hesitant_max"]:
            score -= 0.15
            details["speech_rate_assessment"] = "slow (hesitant)"
        elif speech_rate > thresholds["confident_max"]:
            score -= 0.05
            details["speech_rate_assessment"] = "fast (nervous)"
        else:
            details["speech_rate_assessment"] = "moderate"
        
        # Pitch variance analysis
        pitch_variance = audio_features.get("pitch_variance", 0.3)
        thresholds = self.PROSODIC_THRESHOLDS["pitch_variance"]
        
        if pitch_variance < thresholds["confident_max"]:
            score += 0.15
            details["pitch_assessment"] = "stable (confident)"
        elif pitch_variance > thresholds["hesitant_min"]:
            score -= 0.15
            details["pitch_assessment"] = "variable (uncertain)"
        else:
            details["pitch_assessment"] = "moderate"
        
        # Energy consistency
        energy_variance = audio_features.get("energy_variance", 0.3)
        if energy_variance < 0.3:
            score += 0.1
            details["energy_assessment"] = "consistent"
        elif energy_variance > 0.6:
            score -= 0.1
            details["energy_assessment"] = "inconsistent"
        else:
            details["energy_assessment"] = "moderate"
        
        score = max(0.1, min(0.95, score))
        details["speech_rate_value"] = speech_rate
        details["pitch_variance_value"] = pitch_variance
        details["energy_variance_value"] = energy_variance
        
        return score, details
    
    def _calculate_emotional_adjustment(
        self,
        emotion_analysis: Dict[str, Any]
    ) -> float:
        """Calculate confidence adjustment based on emotional state."""
        adjustment = 0.5
        
        primary_emotion = emotion_analysis.get("primary_emotion", "neutral")
        primary_score = emotion_analysis.get("primary_score", 0.5)
        
        # Emotions that indicate confidence
        confident_emotions = ["confidence", "calm", "joy"]
        
        # Emotions that indicate uncertainty
        uncertain_emotions = ["hesitation", "fear", "sadness", "frustration"]
        
        if primary_emotion in confident_emotions:
            adjustment += primary_score * 0.3
        elif primary_emotion in uncertain_emotions:
            adjustment -= primary_score * 0.3
        
        # Factor in emotional stability
        stability = emotion_analysis.get("emotional_stability", 0.5)
        adjustment += (stability - 0.5) * 0.2
        
        return max(0.1, min(0.95, adjustment))
    
    def _analyze_sentence_structure(self, text: str) -> float:
        """Analyze sentence structure for confidence indicators."""
        if not text:
            return 0.5
        
        score = 0.5
        
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return 0.5
        
        # Check for complete sentences
        complete_sentences = sum(1 for s in sentences if len(s.split()) >= 3)
        completeness_ratio = complete_sentences / len(sentences)
        score += (completeness_ratio - 0.5) * 0.2
        
        # Check for declarative statements (confidence)
        declarative = sum(1 for s in sentences if s.endswith('.') or not s[-1] in '?!')
        declarative_ratio = declarative / len(sentences) if sentences else 0
        score += (declarative_ratio - 0.5) * 0.15
        
        # Check for questions (uncertainty)
        questions = sum(1 for s in sentences if '?' in s)
        question_ratio = questions / len(sentences) if sentences else 0
        score -= question_ratio * 0.1
        
        return max(0.1, min(0.95, score))
    
    def _analyze_vocabulary(self, text: str) -> float:
        """Analyze vocabulary sophistication as confidence indicator."""
        if not text:
            return 0.5
        
        words = re.findall(r'\b\w+\b', text.lower())
        if not words:
            return 0.5
        
        # Unique word ratio
        unique_ratio = len(set(words)) / len(words)
        
        # Average word length
        avg_length = sum(len(w) for w in words) / len(words)
        
        # Sophisticated vocabulary (longer average = more confident typically)
        length_score = min(avg_length / 6, 1.0)  # Normalize around 6 characters
        
        # Combine
        score = 0.3 + unique_ratio * 0.35 + length_score * 0.35
        
        return max(0.1, min(0.95, score))
    
    def _scale_score(self, raw_score: float) -> float:
        """Scale raw score (0-1) to 1-10 range."""
        # Apply sigmoid-like transformation for more natural distribution
        scaled = 1 + raw_score * 9
        
        # Clamp to valid range
        return max(1.0, min(10.0, scaled))
    
    def _get_certainty_level(self, score: float) -> str:
        """Convert numeric score to certainty level."""
        if score >= 8.5:
            return "Very High"
        elif score >= 7.0:
            return "High"
        elif score >= 5.0:
            return "Medium"
        elif score >= 3.0:
            return "Low"
        else:
            return "Very Low"
    
    def _generate_analysis_notes(
        self,
        score: float,
        components: Dict[str, float],
        linguistic_details: Dict[str, Any],
        prosodic_details: Dict[str, Any]
    ) -> List[str]:
        """Generate human-readable analysis notes."""
        notes = []
        
        # Overall assessment
        if score >= 8.0:
            notes.append("Speaker demonstrates high confidence with clear, assertive language")
        elif score >= 6.0:
            notes.append("Speaker shows moderate confidence with some uncertainty markers")
        elif score >= 4.0:
            notes.append("Speaker shows mixed confidence signals")
        else:
            notes.append("Speaker demonstrates significant uncertainty in delivery")
        
        # Component-specific notes
        if components.get("linguistic", 0) > 0.7:
            notes.append("Strong use of confident vocabulary and phrases")
        elif components.get("linguistic", 0) < 0.4:
            notes.append("Frequent use of hedging language and uncertainty markers")
        
        if prosodic_details.get("speech_rate_assessment") == "slow (hesitant)":
            notes.append("Speech rate suggests hesitation or careful consideration")
        elif prosodic_details.get("speech_rate_assessment") == "fast (nervous)":
            notes.append("Rapid speech may indicate nervousness or excitement")
        
        if prosodic_details.get("pitch_assessment") == "stable (confident)":
            notes.append("Stable pitch pattern indicates emotional control")
        elif prosodic_details.get("pitch_assessment") == "variable (uncertain)":
            notes.append("Variable pitch suggests emotional fluctuation")
        
        # Hesitation markers
        hesitation_words = linguistic_details.get("hesitation_words", [])
        if len(hesitation_words) > 3:
            notes.append(f"Multiple hesitation markers detected: {', '.join(hesitation_words[:3])}")
        
        return notes[:5]  # Limit to 5 notes